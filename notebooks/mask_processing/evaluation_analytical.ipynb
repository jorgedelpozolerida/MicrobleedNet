{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models\n",
    "Notebook to evaluate analytically models. \n",
    "\n",
    "It parses the evaluation run log for every model and extracts some basic numbers.\n",
    "It then computes evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "data_dir = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse log file from evaluation on ClearML to obtain metrics calculated during run\n",
    "'''\n",
    "def evaluate_detection(file_path, src):\n",
    "    # Initialize lists to store the extracted data\n",
    "    classification_data = []\n",
    "    counts_data = []\n",
    "    segmentation_data = []\n",
    "    iteration_data = []\n",
    "\n",
    "    current_data = ''\n",
    "    processing = False\n",
    "    iteration = 0\n",
    "\n",
    "    # Function to preprocess and parse the string as a dictionary\n",
    "    def parse_data(string):\n",
    "        # Remove trailing commas in the dictionary string\n",
    "        string = re.sub(r',\\s*}', '}', string)\n",
    "        string = re.sub(r',\\s*\\]', ']', string)\n",
    "        return ast.literal_eval(string)\n",
    "\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"'classification':\" in line:\n",
    "                processing = True\n",
    "                iteration += 1\n",
    "                current_data = line.strip()\n",
    "            elif processing:\n",
    "                current_data += ' ' + line.strip()\n",
    "                # Check if the line ends with '}}' and not followed by a comma\n",
    "                if re.search(r'}\\s*}\\s*$', line.strip()):\n",
    "                    processing = False\n",
    "                    try:\n",
    "                        data_dict = parse_data(current_data)\n",
    "                        iteration_data.append(iteration)\n",
    "                        classification_data.append(data_dict.get('classification', {}))\n",
    "                        counts_dict = data_dict.get('counts', {})\n",
    "                        counts_data.append({k: v[1] for k, v in counts_dict.items()})\n",
    "                        segmentation_data.append(data_dict.get('segmentation', {}))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing data: {e}\")\n",
    "                        print(\"Faulty data:\", current_data)\n",
    "\n",
    "    # Create separate pandas DataFrames\n",
    "    df_classification = pd.DataFrame(classification_data, index=iteration_data)\n",
    "    df_counts = pd.DataFrame(counts_data, index=iteration_data)\n",
    "    df_segmentation = pd.DataFrame(segmentation_data, index=iteration_data)\n",
    "    \n",
    "    df_counts['src'] = src\n",
    "    df_classification['src'] = src\n",
    "    df_segmentation['src'] = src\n",
    "\n",
    "    # Calculating TP, FP, FN\n",
    "    df_counts['TP'] = df_counts['predicted_overlapping_counts']\n",
    "    df_counts['FP'] = df_counts['predicted_counts'] - df_counts['predicted_overlapping_counts']\n",
    "    df_counts['FN'] = df_counts['true_counts'] - df_counts['predicted_overlapping_counts']\n",
    "    \n",
    "    # Cleaning\n",
    "    df_segmentation.replace('nan', np.nan, inplace=True)\n",
    "    df_classification.columns = ['back', 'cmb', 'src']\n",
    "\n",
    "    return df_classification, df_counts, df_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{data_dir}/eval_kdd_all.txt'\n",
    "df_classification1, df_counts1, df_segmentation1 = evaluate_detection(file_path, src=\"KDD_all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back</th>\n",
       "      <th>cmb</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>TP</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>TP</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TN</td>\n",
       "      <td>TP</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TN</td>\n",
       "      <td>TP</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  back cmb      src\n",
       "1   TN  TP  KDD_all\n",
       "2   TN  TP  KDD_all\n",
       "3   TN  TP  KDD_all\n",
       "4   TN  TP  KDD_all"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_counts</th>\n",
       "      <th>predicted_overlapping_counts</th>\n",
       "      <th>true_counts</th>\n",
       "      <th>src</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>KDD_all</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>KDD_all</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>KDD_all</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>KDD_all</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_counts  predicted_overlapping_counts  true_counts      src  TP  \\\n",
       "1                26                             9           11  KDD_all   9   \n",
       "2                31                             5           18  KDD_all   5   \n",
       "3                37                            10           13  KDD_all  10   \n",
       "4                14                             5            6  KDD_all   5   \n",
       "\n",
       "   FP  FN  \n",
       "1  17   2  \n",
       "2  26  13  \n",
       "3  27   3  \n",
       "4   9   1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_0</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>f1_avg</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>specificity_0</th>\n",
       "      <th>specificity_1</th>\n",
       "      <th>specificity_avg</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.437280</td>\n",
       "      <td>0.437280</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.410944</td>\n",
       "      <td>0.410944</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.467223</td>\n",
       "      <td>0.467223</td>\n",
       "      <td>0.467223</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.156255</td>\n",
       "      <td>0.156255</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0.138730</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.178848</td>\n",
       "      <td>0.178848</td>\n",
       "      <td>0.178848</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.466051</td>\n",
       "      <td>0.466051</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.367767</td>\n",
       "      <td>0.367767</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.636027</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.399208</td>\n",
       "      <td>0.399208</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.341695</td>\n",
       "      <td>0.341695</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>KDD_all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1_0      f1_1    f1_avg  precision_0  precision_1  precision_avg  \\\n",
       "1  0.999945  0.437280  0.437280     0.999951     0.410944       0.410944   \n",
       "2  0.999907  0.156255  0.156255     0.999921     0.138730       0.138730   \n",
       "3  0.999968  0.466051  0.466051     0.999984     0.367767       0.367767   \n",
       "4  0.999975  0.399208  0.399208     0.999982     0.341695       0.341695   \n",
       "\n",
       "   recall_0  recall_1  recall_avg  specificity_0  specificity_1  \\\n",
       "1  0.999939  0.467223    0.467223       0.467223       0.999939   \n",
       "2  0.999893  0.178848    0.178848       0.178848       0.999893   \n",
       "3  0.999951  0.636027    0.636027       0.636027       0.999951   \n",
       "4  0.999969  0.480000    0.480000       0.480000       0.999969   \n",
       "\n",
       "   specificity_avg      src  \n",
       "1         0.999939  KDD_all  \n",
       "2         0.999893  KDD_all  \n",
       "3         0.999951  KDD_all  \n",
       "4         0.999969  KDD_all  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_segmentation1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_detection(df_counts, df_f1=None):\n",
    "    # Copying df_counts to a new DataFrame for metric calculations\n",
    "    df = df_counts.copy()\n",
    "\n",
    "    # Calculating TP, FP, FN\n",
    "    TP = df['predicted_overlapping_counts'].sum()\n",
    "    FP = (df['predicted_counts'] - df['predicted_overlapping_counts']).sum()\n",
    "    FN = (df['true_counts'] - df['predicted_overlapping_counts']).sum()\n",
    "\n",
    "    # Calculating metrics\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    PPV = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    F1 = 2 * (PPV * TPR) / (PPV + TPR) if (PPV + TPR) != 0 else 0\n",
    "\n",
    "    # Creating a DataFrame for results\n",
    "    metrics_data = {\n",
    "        'Experiment': df_counts['src'].iloc[0][-1] if 'src' in df_counts else 'N/A',\n",
    "        # 'TP': [TP],\n",
    "        # 'FP': [FP],\n",
    "        # 'FN': [FN],\n",
    "        'TPR': [TPR],\n",
    "        'PPV': [PPV],\n",
    "        'F1': [F1]\n",
    "    }\n",
    "    results_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "    # Additional metrics calculations\n",
    "    results_df['TPavg'] = TP / len(df)\n",
    "    results_df['FPavg'] = FP / len(df)\n",
    "    results_df['FPmedian'] = np.median((df['predicted_counts'] - df['predicted_overlapping_counts']))\n",
    "    results_df['FP/cmb'] = FP / df['true_counts'].sum() if df['true_counts'].sum() != 0 else 0\n",
    "    results_df['FNavg'] = FN / len(df)\n",
    "\n",
    "    # Incorporating F1 from another DataFrame if provided\n",
    "    if df_f1 is not None and 'f1_avg' in df_f1.columns:\n",
    "        results_df['DiceScore'] = df_f1['f1_avg'].mean()\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>TPR</th>\n",
       "      <th>PPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TPavg</th>\n",
       "      <th>FPavg</th>\n",
       "      <th>FPmedian</th>\n",
       "      <th>FP/cmb</th>\n",
       "      <th>FNavg</th>\n",
       "      <th>DiceScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.25</td>\n",
       "      <td>19.75</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment  TPR   PPV    F1  TPavg  FPavg  FPmedian  FP/cmb  FNavg  \\\n",
       "0          l  0.6  0.27  0.37   7.25  19.75      21.5    1.65   4.75   \n",
       "\n",
       "   DiceScore  \n",
       "0       0.36  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = evaluate_detection(df_counts1, df_segmentation1)\n",
    "\n",
    "results_df1.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics\n",
    "Classification is here considered as detecting some microbleed in a usbject with some microbleed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(df):\n",
    "    # Counting the occurrences of each metric\n",
    "    TP = np.sum((df['cmb'] == 'TP'))\n",
    "    FP = np.sum((df['cmb'] == 'FP'))\n",
    "    TN = np.sum((df['cmb'] == 'TN'))\n",
    "    FN = np.sum((df['cmb'] == 'FN'))\n",
    "\n",
    "    # Calculating metrics\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    PPV = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    F1 = 2 *( (PPV * TPR) / (PPV + TPR))  if (PPV + TPR) != 0 else 0,\n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    ACC = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) != 0 else 0\n",
    "\n",
    "    # Creating a DataFrame for results\n",
    "    metrics_data = {\n",
    "        'Experiment': df['src'].iloc[0][-1],\n",
    "        'TPR': [TPR],\n",
    "        'PPV': [PPV],\n",
    "        'F1': [F1][0],\n",
    "        'TNR': [TNR],\n",
    "        'ACC': [ACC]\n",
    "    }\n",
    "    results_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    return results_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>TPR</th>\n",
       "      <th>PPV</th>\n",
       "      <th>F1</th>\n",
       "      <th>TNR</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment  TPR  PPV   F1  TNR  ACC\n",
       "0          l  1.0  1.0  1.0    0  1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1 = evaluate_classification(df_classification1)\n",
    "\n",
    "results_df1.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cerebriu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
